{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\anaconda3\\lib\\site-packages\\requests\\__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from datetime import datetime, timedelta\n",
    "from dash import dcc, html, Dash, Input, Output, State, ALL\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Centro__de_Trabajo = \"CENTRO DE DISTRIBUCION\" #OFICINA APOYO A TIENDAS     #CENTRO DE DISTRIBUCION       #ALMACEN CALLE 80j´-´-ç-j\n",
    "Id_Centro_Costo = \"O003100201\"  #GERENCIA COMERCIAL - O003003001 # AV. 68 SUR PRINCIPAL - O003100201\n",
    "Cargo = \"VENDEDOR\" #CAJERO    #VENDEDOR\n",
    "#Centro_Costo_Gerentes = \"GERENCIA COMERCIAL\" \n",
    "#Macrogerencia = \"GERENCIA COMERCIAL Y MARKETING\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Filtro = Cargo\n",
    "nombre_columna = \"Cargo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = {\n",
    "    \"Retirados\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Data empleado/12. Empleados Diciembre 2023 Talento.xlsx\", \n",
    "    \"Auxilios\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Compensación/Prestamos y Auxilios/Prestamos & Auxilios 2023.xlsx\",  \n",
    "    \"Prestamos\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Compensación/Prestamos y Auxilios/Prestamos & Auxilios 2023.xlsx\", \n",
    "    \"Empleado_Noviembre_2023_Activo\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Data empleado/11. Empleados Noviembre 2023 Talento.xlsx\", \n",
    "    \"Empleado_Diciembre_2023_Consolidado\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Data empleado/12. Empleados Diciembre 2023 Talento.xlsx\", \n",
    "    \"Empleado_Diciembre_2023_Activo\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Data empleado/12. Empleados Diciembre 2023 Talento.xlsx\",\n",
    "    \"Rotacion_Interna_Acumulado\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Data empleado/ROTACION INTERNA ACUMULADA.xlsx\", \n",
    "    \"Finalizacion_Curso\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Desarrollo y talento humano/Formación/finalizacin_de_cursos_Dic 2023.xlsx\", \n",
    "    \"Solicitudes\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Desarrollo y talento humano/Selección/Sodimac Colombia - Reporte de solicitudes  20231227.xlsx\", \n",
    "    \"Vacantes_Totales\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Desarrollo y talento humano/Selección/reporte_vacantes_totales.xlsx\", \n",
    "    \"Base_Data\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Relaciones laborales y SST/Accidentalidad/Base para data 12-2023.xlsx\", \n",
    "    \"Enfermedades_Colaborales\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Relaciones laborales y SST/Accidentalidad/ENFERMEDADES LABORALES CONSOLIDADO 12-2023.xlsx\", \n",
    "    \"Sindicato\": \"C:/Users/Asus/Desktop/SODIMAC/BASE DE DATOS/Data/Relaciones laborales y SST/Sindicatos/INFORMACION SINDICAL.xlsx\" \n",
    "}\n",
    "\n",
    "def read(retirados_url, Auxilios_url, Prestamos_url, Empleado_Noviembre_Activo_url, Empleado_Diciembre_Consolidado_url, Empleado_Diciembre_Activo_url, Rotacion_Interna_Acumulado_url, Finalizacion_Curso_url, Solicitudes_url, Vacantes_Totales_url, Base_Data_url, Enfermedades_Colaborales_url, Sindicato_url):\n",
    "    retirados = pd.read_excel(retirados_url, sheet_name=\"Retirados\")\n",
    "    auxilios = pd.read_excel(Auxilios_url, sheet_name= \"BASE DE AUXILIOS\")\n",
    "    prestamos = pd.read_excel(Prestamos_url, sheet_name= \"BASE DE PRESTAMOS\")\n",
    "    empleado_noviembre_2023_activo = pd.read_excel(Empleado_Noviembre_Activo_url, sheet_name=\"Activos\")\n",
    "    empleado_diciembre_2023_consolidado = pd.read_excel(Empleado_Diciembre_Consolidado_url, sheet_name=\"Consolidado\")\n",
    "    empleado_diciembre_2023_activo = pd.read_excel(Empleado_Diciembre_Activo_url, sheet_name=\"Activos\")\n",
    "    rotacion_interna_acomulado  = pd.read_excel(Rotacion_Interna_Acumulado_url, sheet_name=\"INTERNA\")\n",
    "    finalizacio_curso = pd.read_excel(Finalizacion_Curso_url)\n",
    "    solicitudes = pd.read_excel(Solicitudes_url)\n",
    "    #vacantes_ofertas = pd.read_excel(r\"C:\\Users\\Asus\\Desktop\\SODIMAC\\BASE DE DATOS\\Data\\Desarrollo y talento humano\\Selección\\Sodimac Colombia - Reporte de Vacantes 20231227.xlsx\", sheet_name=\"Ofertas\")\n",
    "\n",
    "    #vacantes_contratados = pd.read_excel(r\"C:\\Users\\Asus\\Desktop\\SODIMAC\\BASE DE DATOS\\Data\\Desarrollo y talento humano\\Selección\\Sodimac Colombia - Reporte de Vacantes 20231227.xlsx\", sheet_name=\"Contratados\")\n",
    "    vacantes_totales = pd.read_excel(Vacantes_Totales_url,sheet_name=\"27.12.2023\")\n",
    "    basse_data = pd.read_excel(Base_Data_url)\n",
    "    enfermedades_colaborales = pd.read_excel(Enfermedades_Colaborales_url,sheet_name =\"Enfermedades laborales\" )\n",
    "    sindicato = pd.read_excel(Sindicato_url, sheet_name= \"INFORMACION SINDICAL\")\n",
    "\n",
    "    return retirados, auxilios, prestamos, empleado_noviembre_2023_activo, empleado_diciembre_2023_consolidado, empleado_diciembre_2023_activo, rotacion_interna_acomulado, finalizacio_curso, solicitudes, vacantes_totales, basse_data, enfermedades_colaborales, sindicato\n",
    "\n",
    "def limpieza(retirados, auxilios, prestamos, empleado_noviembre_2023_activo, empleado_diciembre_2023_consolidado, empleado_diciembre_2023_activo, rotacion_interna_acomulado, finalizacio_curso, solicitudes, vacantes_totales, basse_data, enfermedades_colaborales, sindicato):\n",
    "    empleado_noviembre_2023_activo.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    auxilios.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    prestamos.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    empleado_diciembre_2023_consolidado.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    empleado_diciembre_2023_activo.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    rotacion_interna_acomulado.rename(columns={'Nº de documento C.C.': 'ID'}, inplace=True)\n",
    "    finalizacio_curso.rename(columns={'NÃºmero de ID del usuario': 'ID'}, inplace=True)\n",
    "    basse_data.rename(columns={'Cédula': 'ID'}, inplace=True)\n",
    "    enfermedades_colaborales.rename(columns={'Cédula': 'ID'}, inplace=True)\n",
    "    sindicato.rename(columns={'Cédula': 'ID'}, inplace=True)\n",
    "    \n",
    "    vacantes_totales.rename(columns={'CARGO PLANTA':'Cargo'},inplace=True)\n",
    "    finalizacio_curso = finalizacio_curso[[\"ID\", \"Nombre del Curso\", \"CrÃ©ditos\",\"CategorÃ­a del Curso\",\"CalificaciÃ³n\"]]\n",
    "    return retirados, auxilios, prestamos, empleado_noviembre_2023_activo, empleado_diciembre_2023_consolidado, empleado_diciembre_2023_activo, rotacion_interna_acomulado, finalizacio_curso, solicitudes, vacantes_totales, basse_data, enfermedades_colaborales, sindicato\n",
    "\n",
    "def calculos(Filtro,nombre_columna,variables):\n",
    "    retirados = variables[0]\n",
    "    auxilios = variables[1]\n",
    "    prestamos = variables[2]\n",
    "    empleado_noviembre_2023_activo = variables[3]\n",
    "    empleado_diciembre_2023_consolidado = variables[4]\n",
    "    empleado_diciembre_2023_activo = variables[5]\n",
    "    rotacion_interna_acomulado = variables[6]\n",
    "    finalizacio_curso = variables[7]\n",
    "    solicitudes = variables[8]\n",
    "    vacantes_totales = variables[9]\n",
    "    basse_data = variables[10]\n",
    "    enfermedades_colaborales = variables[11]\n",
    "    sindicato  = variables[12]\n",
    "\n",
    "    tamaño_gerencia = empleado_diciembre_2023_activo.groupby(nombre_columna).size()[Filtro]\n",
    "    tamaño_gerencia\n",
    "\n",
    "\n",
    "    # ## **Compensación**\n",
    "\n",
    "    # ### **Auxilios**\n",
    "\n",
    "    # Vamos a filtrar la base principal, por los empleados que iniciarón antes del 2023\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    empleado_diciembre_2023_activo['Fecha de Ingreso'] = pd.to_datetime(empleado_diciembre_2023_activo['Fecha de Ingreso'], format='%d/%m/%Y')\n",
    "\n",
    "    # Filtrar los valores antes del año 2023\n",
    "    result = empleado_diciembre_2023_activo[empleado_diciembre_2023_activo['Fecha de Ingreso'].dt.year < 2023]\n",
    "\n",
    "\n",
    "    # Conexion entre base y auxilios\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Realiza la fusión de los datos\n",
    "    conex_auxilio = pd.merge(result, auxilios, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo = conex_auxilio.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        aux = grupo.size()[Filtro]\n",
    "        auxil_data_frame = conex_auxilio.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    recuento_uniq = auxil_data_frame['ID'].nunique()\n",
    "    auxi = (recuento_uniq/tamaño_gerencia)*100\n",
    "   \n",
    "\n",
    "\n",
    "    # ### **Prestamos**\n",
    "\n",
    "\n",
    "\n",
    "    # Realiza la fusión de los datos\n",
    "    conex_prestamos = pd.merge(empleado_diciembre_2023_activo, prestamos, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo = conex_prestamos.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        pres = grupo.size()[Filtro]\n",
    "        prestamos_data_frame = conex_prestamos.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "       \n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "\n",
    "    I_total = empleado_diciembre_2023_activo[pd.to_datetime(empleado_diciembre_2023_activo['Fecha de Ingreso']).dt.year == 2023]\n",
    "    I_total_diciembre_2023 = I_total[pd.to_datetime(I_total['Fecha de Ingreso']).dt.month == 12]\n",
    "\n",
    "\n",
    "    grupo_data = I_total_diciembre_2023.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_data.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        rot = grupo_data.size()[Filtro]\n",
    "        base_ingreso = I_total_diciembre_2023.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "        base_ingreso_nueva = 1\n",
    "    else:\n",
    "        base_ingreso_nueva = 0\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    # Calcularemos retirados para todas las personas que se fueron en  diciembre \n",
    "\n",
    "    # In[78]:\n",
    "\n",
    "\n",
    "    R = retirados[pd.to_datetime(retirados['Fecha de Retiro']).dt.year == 2023]\n",
    "    R_diciembre_2023 = R[pd.to_datetime(R['Fecha de Retiro']).dt.month == 12]\n",
    "\n",
    "\n",
    "    # In[79]:\n",
    "\n",
    "\n",
    "    if nombre_columna == \"Centro Costo Gerentes\":\n",
    "        nombre_columna_unico = \"Centro Costo\" \n",
    "        grupo_data = R_diciembre_2023.groupby(nombre_columna_unico)\n",
    "    elif nombre_columna == \"Centro  de Trabajo\":\n",
    "        nombre_columna_unico = \"Lugar de Trabajo\"\n",
    "    else:\n",
    "        nombre_columna_unico = nombre_columna\n",
    "    grupo_data = R_diciembre_2023.groupby(nombre_columna_unico)\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_data.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        base_retiros = R_diciembre_2023.query(f\"`{nombre_columna_unico}` == '{Filtro}'\")\n",
    "        \n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    # empleados existentes en Noviembre\n",
    "\n",
    "    # In[80]:\n",
    "\n",
    "\n",
    "    existentes_noviembre = empleado_noviembre_2023_activo.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_data.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        existentes_novi = empleado_noviembre_2023_activo.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "        \n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    # empleados existentes en Diciembre\n",
    "\n",
    "    # In[81]:\n",
    "\n",
    "\n",
    "    existentes_noviembre = empleado_diciembre_2023_activo.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_data.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        existentes_dic = empleado_diciembre_2023_activo.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "       \n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    # FORMULA\n",
    "\n",
    "    # In[82]:\n",
    "\n",
    "\n",
    "    PE =( existentes_novi.shape[0] +existentes_dic.shape[0])/2\n",
    "\n",
    "\n",
    "    # In[83]:\n",
    "\n",
    "\n",
    "    if base_ingreso_nueva != 0:\n",
    "        indice_rot = 100 - (((base_retiros.shape[0] + base_ingreso.shape[0])/2)*100)/PE\n",
    "        \n",
    "    else:\n",
    "        indice_rot = 100 - (((base_retiros.shape[0] + base_ingreso_nueva)/2)*100)/PE\n",
    "        \n",
    "\n",
    "\n",
    "    # FORMULA GENERAL\n",
    "\n",
    "    # In[84]:\n",
    "\n",
    "\n",
    "    indic_gene = (((I_total_diciembre_2023.shape[0] + R_diciembre_2023.shape[0] )/2)*100)/((empleado_noviembre_2023_activo.shape[0] + empleado_diciembre_2023_activo.shape[0])/2)\n",
    "\n",
    "\n",
    "    # Realiza la fusión de los datos\n",
    "    conex_curso = pd.merge(empleado_diciembre_2023_activo, finalizacio_curso, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo_curso = conex_curso.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_curso.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        rot = grupo_curso.size()[Filtro]\n",
    "        base_formacion = conex_curso.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "    mascara = base_formacion['CategorÃ­a del Curso'] == \"ONBOARDING\"\n",
    "    # Aplicar la máscara booleana para filtrar el DataFrame\n",
    "    resultado = base_formacion[mascara]\n",
    "    Cursos_realizados = resultado.groupby(\"ID\").size()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    prom_cantidad_cursos = resultado.groupby(\"ID\").size().mean()\n",
    "    porcentaje_cursos = ((prom_cantidad_cursos)/12)*100\n",
    "    porcentaje_cursos\n",
    "\n",
    "    # Realiza la fusión de los datos\n",
    "    conex_basedata = pd.merge(empleado_diciembre_2023_activo, basse_data, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo_data = conex_basedata.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_data.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        rot = grupo_data.size()[Filtro]\n",
    "        na = conex_basedata.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "        na_nueva = 1\n",
    "    else:\n",
    "        na_nueva = 0\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "    if na_nueva != 0:\n",
    "        sanas = ((tamaño_gerencia - na.shape[0])/tamaño_gerencia)*100\n",
    "    else:\n",
    "        sanas = ((tamaño_gerencia -0)/tamaño_gerencia)*100\n",
    "\n",
    "    if na_nueva == 0:\n",
    "        promedio = 0\n",
    "    else:\n",
    "        basse_data_copia_sin_na = na.dropna(subset=['% Productividad'])\n",
    "        filas_filtradas_100 = basse_data_copia_sin_na[basse_data_copia_sin_na['% Productividad'].str.contains('100%')].shape[0]\n",
    "        filas_filtradas_75 = basse_data_copia_sin_na[basse_data_copia_sin_na['% Productividad'].str.contains('75%')].shape[0]\n",
    "        filas_filtradas_50 = basse_data_copia_sin_na[basse_data_copia_sin_na['% Productividad'].str.contains('50%')].shape[0]\n",
    "        filas_filtradas_0 = basse_data_copia_sin_na[basse_data_copia_sin_na['% Productividad'].str.contains('No cumple%')].shape[0]\n",
    "        promedio = (filas_filtradas_100*100 + filas_filtradas_75*75 + filas_filtradas_50*50 +filas_filtradas_0*0)/(filas_filtradas_100+filas_filtradas_75+filas_filtradas_50+filas_filtradas_0)\n",
    "\n",
    "    conex_colab = pd.merge(empleado_diciembre_2023_activo, enfermedades_colaborales, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo_colab = conex_colab.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_colab.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        rot = grupo_colab.size()[Filtro]\n",
    "        base_colab = conex_colab.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "    # Realiza la fusión de los datos\n",
    "    conex_sindi = pd.merge(empleado_diciembre_2023_activo, sindicato, on='ID')\n",
    "\n",
    "    # Agrupa los datos por la columna deseada\n",
    "    grupo_colab = conex_sindi.groupby(nombre_columna)\n",
    "\n",
    "    # Verifica si el valor filtrado está presente en el índice\n",
    "    if Filtro in grupo_colab.groups:\n",
    "        # Obtén los datos para el valor filtrado\n",
    "        rot = grupo_colab.size()[Filtro]\n",
    "        base_sindi2 = conex_sindi.query(f\"`{nombre_columna}` == '{Filtro}'\")\n",
    "        base_sindi2_nueva = 1\n",
    "    else:\n",
    "        # Imprime un mensaje indicando que no hay datos disponibles para el valor filtrado\n",
    "        base_sindi2_nueva = 0\n",
    "        print(f\"No hay datos disponibles para {Filtro}.\")\n",
    "\n",
    "\n",
    "\n",
    "    if base_sindi2_nueva != 0:\n",
    "        no_pertenece = ((tamaño_gerencia - base_sindi2.shape[0])/tamaño_gerencia)*100\n",
    "    else:\n",
    "        no_pertenece = ((tamaño_gerencia - 0)/tamaño_gerencia)*100\n",
    "\n",
    "    return [no_pertenece, sanas, promedio, porcentaje_cursos, auxi, indice_rot]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = url.values()\n",
    "datos = read(*valores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_limpios = limpieza(*datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f03a395d00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import Dash, html, dcc, Input, Output, State, ALL\n",
    "import base64\n",
    "import io\n",
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "def read_and_clean(file_path):\n",
    "    # Usar un mapeo basado en los nombres de los archivos para saber cómo procesar cada uno\n",
    "    if \"Retirados\" in file_path:\n",
    "        df = pd.read_excel(file_path, sheet_name=\"Retirados\")\n",
    "        df.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    elif \"Auxilios\" in file_path:\n",
    "        df = pd.read_excel(file_path, sheet_name=\"BASE DE AUXILIOS\")\n",
    "        df.rename(columns={'Número de Identificación': 'ID'}, inplace=True)\n",
    "    # Añadir más condiciones según sea necesario para otros tipos de archivos\n",
    "    return df\n",
    "\n",
    "prueba = datos_limpios\n",
    "def filtros():\n",
    "    global prueba  # Nota: Intenta evitar usar variables globales\n",
    "    opciones_1 = [\"Centro de Trabajo\", \"Id Centro Costo\", \"Cargo\", \"Centro Costo Gerentes\", \"Macrogerencia\"]\n",
    "    opciones_2 = {\n",
    "        \"Centro de Trabajo\": [\"OFICINA APOYO A TIENDAS\", \"CENTRO DE DISTRIBUCION\", \"ALMACEN CALLE 80\"],\n",
    "        \"Id Centro Costo\": [\"O003003001\", \"O003100201\"],\n",
    "        \"Cargo\": [\"CAJERO\", \"VENDEDOR\"],\n",
    "        \"Centro Costo Gerentes\": [\"GERENCIA COMERCIAL\"],\n",
    "        \"Macrogerencia\": [\"GERENCIA COMERCIAL Y MARKETING\"]\n",
    "    }\n",
    "\n",
    "    app = Dash(__name__, suppress_callback_exceptions=True)\n",
    "\n",
    "    def generate_upload_space(id_prefix, num_spaces):\n",
    "        nombre_variables = [\n",
    "            \"Retirados\", \"Auxilios\", \"Prestamos\", \"Empleado_Noviembre_2023_Activo\",\n",
    "            \"Empleado_Diciembre_2023_Consolidado\", \"Empleado_Diciembre_2023_Activo\",\n",
    "            \"Rotacion_Interna_Acumulado\", \"Finalizacion_Curso\", \"Solicitudes\",\n",
    "            \"Vacantes_Totales\", \"Base_Data\", \"Enfermedades_Colaborales\", \"Sindicato\"\n",
    "        ]\n",
    "\n",
    "        upload_spaces = []\n",
    "        for i in range(num_spaces):\n",
    "            upload_space = html.Div([\n",
    "                html.Label(nombre_variables[i]),\n",
    "                dcc.Upload(\n",
    "                    id={'type': 'upload', 'index': i},\n",
    "                    children=html.Div(['Arrastra y suelta o ', html.A('selecciona un archivo')]),\n",
    "                    style={\n",
    "                        'width': '100%', 'height': '60px', 'lineHeight': '60px',\n",
    "                        'borderWidth': '1px', 'borderStyle': 'dashed',\n",
    "                        'borderRadius': '5px', 'textAlign': 'center', 'margin': '10px'\n",
    "                    },\n",
    "                    multiple=False\n",
    "                ),\n",
    "                html.Div(id={'type': 'upload-success-message', 'index': i}),\n",
    "                html.Hr()\n",
    "            ])\n",
    "            upload_spaces.append(upload_space)\n",
    "        return upload_spaces\n",
    "\n",
    "    def save_file(contents, filename):\n",
    "        # Guarda el archivo y luego llama a read_and_clean\n",
    "        data = contents.encode(\"utf8\").split(b\";base64,\")[1]\n",
    "        file_path = os.path.join(tempfile.gettempdir(), filename)\n",
    "        with open(file_path, \"wb\") as fp:\n",
    "            fp.write(base64.decodebytes(data))\n",
    "        df = read_and_clean(file_path)  # Procesa el archivo justo después de guardarlo\n",
    "        return df.describe()  # Por ejemplo, devolver un resumen del DataFrame\n",
    "\n",
    "    @app.callback(\n",
    "        Output({'type': 'upload-success-message', 'index': ALL}, 'children'),\n",
    "        Input({'type': 'upload', 'index': ALL}, 'contents'),\n",
    "        State({'type': 'upload', 'index': ALL}, 'filename')\n",
    "    )\n",
    "    def update_uploaded_files(contents, filenames):\n",
    "        if not contents:\n",
    "            return [html.Div(\"No se ha cargado ningún archivo aún.\")]\n",
    "        results = []\n",
    "        for content, filename in zip(contents, filenames):\n",
    "            if content:\n",
    "                result = save_file(content, filename)\n",
    "                results.append(html.Div(f\"Resumen de {filename}: {result}\"))\n",
    "            else:\n",
    "                results.append(html.Div(\"No se cargó archivo.\"))\n",
    "        return results\n",
    "\n",
    "    app.layout = html.Div([\n",
    "        dcc.Tabs(id='tabs-example', value='tab-1', children=[\n",
    "            dcc.Tab(label='Cargar archivos', value='tab-1'),\n",
    "            dcc.Tab(label='Gráfica Radial', value='tab-2'),\n",
    "        ]),\n",
    "        html.Div(id='tabs-content')\n",
    "    ])\n",
    "\n",
    "    @app.callback(\n",
    "        Output('tabs-content', 'children'),\n",
    "        Input('tabs-example', 'value')\n",
    "    )\n",
    "    def render_content(tab):\n",
    "        if tab == 'tab-1':\n",
    "            return html.Div([\n",
    "                html.H2('Carga de archivos'),\n",
    "                *generate_upload_space('upload-data', 13)\n",
    "            ])\n",
    "        elif tab == 'tab-2':\n",
    "            return html.Div([\n",
    "                dcc.Dropdown(\n",
    "                    id='filtro-dropdown-1',\n",
    "                    options=[{'label': filtro, 'value': filtro} for filtro in opciones_1],\n",
    "                    value=opciones_1[0]\n",
    "                ),\n",
    "                dcc.Dropdown(id='filtro-dropdown-2'),\n",
    "                dcc.Graph(id='grafico-radial')\n",
    "            ])\n",
    "\n",
    "    @app.callback(\n",
    "        Output('filtro-dropdown-2', 'options'),\n",
    "        Input('filtro-dropdown-1', 'value')\n",
    "    )\n",
    "    def update_options(selected_filter):\n",
    "        if selected_filter:\n",
    "            return [{'label': val, 'value': val} for val in opciones_2[selected_filter]]\n",
    "        return []\n",
    "\n",
    "    @app.callback(\n",
    "        Output('grafico-radial', 'figure'),\n",
    "        [Input('filtro-dropdown-1', 'value'), \n",
    "         Input('filtro-dropdown-2', 'value')]\n",
    "    )\n",
    "    def update_graph(filtro_1, filtro_2):\n",
    "        if filtro_1 and filtro_2:\n",
    "            # Suponiendo que 'calculos' es una función definida que procesa los datos\n",
    "            datos = calculos(filtro_2, filtro_1, prueba)\n",
    "            df = pd.DataFrame([datos], columns=[\"Sindicato\", 'Incapacidad', 'Product. Incapacidad', 'Educación', 'Auxilios', 'Índice de rotación'])\n",
    "            fig = px.scatter_polar(df, title=f\"{filtro_1} - {filtro_2}\", labels={\"index\": \"Categoría\"}, theta=df.columns, r=df.iloc[0])\n",
    "            fig.update_traces(fill='toself')\n",
    "            return fig\n",
    "        # Si algún filtro no está seleccionado, devolver un gráfico vacío\n",
    "        return {'data': [], 'layout': {}}\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        app.run_server(debug=True, port=8052)\n",
    "\n",
    "# Ejecución de la función\n",
    "filtros()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
